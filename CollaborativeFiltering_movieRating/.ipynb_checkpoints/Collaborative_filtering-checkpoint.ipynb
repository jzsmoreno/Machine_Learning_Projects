{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaborative Filtering - Predicting Movie Ratings (MovieLens Datset) By nirvana43p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is about the implementation in pytorch of a Collaborative filtering algorithm in order to predict movie ratings (MovieLens Dataset).\n",
    "\n",
    "Description: \n",
    "    - MovieLens is a tabular data containing the user ID, movie ID and movie ratings made by the users \n",
    "    - The objective is to predict the movie ratings and recommend movies unseen by the users.\n",
    "\n",
    "We´re going to use the MovieLens 100K dataset, which has 100,000 movie reviews. \n",
    "\n",
    "author: Jorge Ivan Avalos Lopez\n",
    "- python: 3.8.3\n",
    "- pytorch: 1.6.0\n",
    "- sklearn: 0.23.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.- Pre-proccesing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u.data', 'u.item']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shelve\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "dataPath = \"./Data/\"\n",
    "os.listdir(dataPath) # Lets check the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User  Movie  Rating  Timestamp\n",
       "0   196    242       3  881250949\n",
       "1   186    302       3  891717742\n",
       "2    22    377       1  878887116\n",
       "3   244     51       2  880606923\n",
       "4   166    346       1  886397596"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "data = pd.read_csv(dataPath+\"u.data\", delimiter=\"\\t\", header=None,\n",
    "                       names=[\"User\",\"Movie\",\"Rating\",\"Timestamp\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype\n",
      "---  ------     --------------   -----\n",
      " 0   User       100000 non-null  int64\n",
      " 1   Movie      100000 non-null  int64\n",
      " 2   Rating     100000 non-null  int64\n",
      " 3   Timestamp  100000 non-null  int64\n",
      "dtypes: int64(4)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "data.info() # Let´s check the dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, 4, 5], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"Rating\"].unique() # lets check the reitings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Movie</th>\n",
       "      <th>7</th>\n",
       "      <th>15</th>\n",
       "      <th>24</th>\n",
       "      <th>34</th>\n",
       "      <th>39</th>\n",
       "      <th>45</th>\n",
       "      <th>50</th>\n",
       "      <th>56</th>\n",
       "      <th>64</th>\n",
       "      <th>69</th>\n",
       "      <th>...</th>\n",
       "      <th>937</th>\n",
       "      <th>947</th>\n",
       "      <th>988</th>\n",
       "      <th>1039</th>\n",
       "      <th>1040</th>\n",
       "      <th>1047</th>\n",
       "      <th>1139</th>\n",
       "      <th>1215</th>\n",
       "      <th>1217</th>\n",
       "      <th>1267</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Movie  7     15    24    34    39    45    50    56    64    69    ...  937   \\\n",
       "User                                                               ...         \n",
       "3       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "5       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "13      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "16      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "22      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "868     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "880     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "911     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "919     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
       "924     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   4.0   NaN  ...   NaN   \n",
       "\n",
       "Movie  947   988   1039  1040  1047  1139  1215  1217  1267  \n",
       "User                                                         \n",
       "3       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "5       NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "13      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "16      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "22      NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "868     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "880     NaN   NaN   NaN   NaN   3.0   NaN   NaN   NaN   NaN  \n",
       "911     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "919     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "924     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[92 rows x 92 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subCrosstable\n",
    "# lets take random sample\n",
    "data_sample = data.sample(frac=0.001)\n",
    "cross_tabulated = pd.crosstab(data_sample.User,data_sample.Movie,\n",
    "                                  values=data_sample.Rating,aggfunc=\"first\") \n",
    "cross_tabulated # we have a lot NaN values, it means non-raiting movies by one user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Four Rooms (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Get Shorty (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Copycat (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Movie              Title\n",
       "0      1   Toy Story (1995)\n",
       "1      2   GoldenEye (1995)\n",
       "2      3  Four Rooms (1995)\n",
       "3      4  Get Shorty (1995)\n",
       "4      5     Copycat (1995)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the mapping of movie and its name\n",
    "movies = pd.read_csv(dataPath+\"u.item\",delimiter=\"|\",encoding=\"latin-1\",\n",
    "                         header=None,usecols=(0,1),names=[\"Movie\",\"Title\"])\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Movie</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>875747190</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>226</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>883888671</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>879138235</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>306</td>\n",
       "      <td>242</td>\n",
       "      <td>5</td>\n",
       "      <td>876503793</td>\n",
       "      <td>Kolya (1996)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User  Movie  Rating  Timestamp         Title\n",
       "0   196    242       3  881250949  Kolya (1996)\n",
       "1    63    242       3  875747190  Kolya (1996)\n",
       "2   226    242       5  883888671  Kolya (1996)\n",
       "3   154    242       3  879138235  Kolya (1996)\n",
       "4   306    242       5  876503793  Kolya (1996)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets join data and movies by Movie column\n",
    "ratings = data.merge(movies,on=\"Movie\")\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we substract one to each User and Movie because the embedding matrix requiered\n",
    "# Note: This is important, because if User or Movie have not a \"0\" in one record, the embedding matrix won´t work and launch an error\n",
    "ratings[\"User\"] = ratings[\"User\"] - 1\n",
    "ratings[\"Movie\"] = ratings[\"Movie\"] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100000.000000\n",
       "mean        424.530130\n",
       "std         330.798356\n",
       "min           0.000000\n",
       "25%         174.000000\n",
       "50%         321.000000\n",
       "75%         630.000000\n",
       "max        1681.000000\n",
       "Name: Movie, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ratings[\"User\"].describe() # we observe that user has min value of 0\n",
    "ratings[\"Movie\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We save the dataFrame\n",
    "shelve_data = shelve.open(dataPath+\"ratings.db\")\n",
    "try:\n",
    "    shelve_data[\"ratings\"] = ratings\n",
    "finally:\n",
    "    shelve_data.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.- Building movieDataset Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler, Adam\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shelve\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class movieDataset(Dataset):\n",
    "    \n",
    "    \"\"\" __init__ method creation\n",
    "    \n",
    "        Args:\n",
    "            path (string) : Define the path where the data is.\n",
    "            transform (Class) : Define a transformation of the dataset\n",
    "            train (Bool) : Define training or test data\n",
    "            split_data (Dict) : Define defaul parameters to train_test_split function\n",
    "                                random state must be the number for training and validation \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,path,transform = None, train = True, \n",
    "                 split_data = {\"test_size\" : 0.2, \"random_state\" : None}):\n",
    "        super(movieDataset,self).__init__()\n",
    "        \n",
    "        self._path = path\n",
    "        self._transform = transform\n",
    "        self._train = train\n",
    "        self._split_data = split_data\n",
    "        \n",
    "        # Read the dataset from shelve object\n",
    "        with shelve.open(path) as data:\n",
    "            self._ratings = data[\"ratings\"] # Pandas DataFrame\n",
    "        \n",
    "        # Split X_data (input vector - feature vector) and Y_data(output_vector - label vector)\n",
    "        # from de dataset\n",
    "        self._x_data, self._y_data = self._ratings[[\"User\",\"Movie\"]], self._ratings[[\"Rating\"]]\n",
    "        \n",
    "        # Split dataset into train and test using train_test_split\n",
    "        self._x_train, self._x_val, self._y_train, self._y_val = train_test_split(self._x_data,self._y_data, \n",
    "                                                                                    test_size = self._split_data[\"test_size\"],\n",
    "                                                                                    random_state = self._split_data[\"random_state\"])\n",
    "        \n",
    "        # get number of users\n",
    "        self.n_users = self._ratings[\"User\"].nunique()\n",
    "        # get number of movies \n",
    "        self.n_movies = self._ratings[\"Movie\"].nunique()\n",
    "        \n",
    "        \n",
    "         # Get the cardinality of the dataset\n",
    "        if self._train:\n",
    "            self._n_samples = len(self._x_train)\n",
    "        else:\n",
    "            self._n_samples = len(self._x_val)\n",
    "        \n",
    "        \n",
    "        \"\"\" __getitem__ magic method to index the object\n",
    "        \n",
    "        Args:\n",
    "            index (Integer) : Define the index\n",
    "            \n",
    "        Return:\n",
    "            sample (Tuple) : (input vector, label vector)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        if self._train:\n",
    "            sample = self._x_train.iloc[index,:], self._y_train.iloc[index,:]\n",
    "        else:\n",
    "            sample = self._x_val.iloc[index,:], self._y_val.iloc[index,:]\n",
    "        \n",
    "        if self._transform:\n",
    "            sample = self._transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    \"\"\" __len__ magic method to len the object\n",
    "    \n",
    "    \"\"\"\n",
    "    def __len__(self):\n",
    "        return self._n_samples\n",
    "                \n",
    "\n",
    "class ToTensor:\n",
    "    \n",
    "    \"\"\" __call__ magic method to recive objects and transform them \n",
    "        \n",
    "        Return: \n",
    "            (torch.Tensor, torch.Tensor)\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        x, y = sample\n",
    "        return torch.tensor(x.values).long(), torch.squeeze(torch.tensor(y.values)).to(torch.float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.- Building a collaborative Filtering model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollFilt(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users,n_movies,n_factors,output_range=(0,5.5)):\n",
    "        super(CollFilt,self).__init__()\n",
    "        self.output_range = output_range\n",
    "        self.user_factors = nn.Embedding(n_users, n_factors)\n",
    "        self.user_bias = nn.Embedding(n_users, 1)\n",
    "        \n",
    "        self.movie_factors = nn.Embedding(n_movies, n_factors)\n",
    "        self.movie_bias = nn.Embedding(n_movies, 1) \n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    \n",
    "    def forward(self,t_input):\n",
    "        users_t = t_input[:,0]\n",
    "        movies_t = t_input[:,1]\n",
    "        users = self.user_factors(users_t)\n",
    "        movies = self.movie_factors(movies_t)\n",
    "        dotProd = (users*movies).sum(dim=1)\n",
    "        dotProd += self.user_bias(users_t)[:,0] + self.movie_bias(movies_t)[:,0]\n",
    "        return self.sigmoid_range(dotProd,self.output_range)        \n",
    "    \n",
    "    def sigmoid_range(self,t_input,output_range):\n",
    "        min_val, max_val = output_range\n",
    "        return (max_val - min_val)*self.sigmoid(t_input) + min_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.- Training and Evaluating the Colaborative Filtering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, loss, optimizer, scheduler ,data_train, data_val,\n",
    "                num_epochs = 10, batch_size = 128, device = 'cuda'):\n",
    "    \n",
    "    \"\"\" Training Model\n",
    "        Args:\n",
    "            model (nn.Module) : Model to train, model must be in gpu or cpu \n",
    "            loss (nn.lossFunction) : Loss function to minimize\n",
    "            optimizer (torch.optim.optimizer) : optimizer algorithm\n",
    "            data_train (torch.utils.data.Dataset) : a Dataset instance of the data train\n",
    "            data_test (torch.utils.data.Dataset) : a Dataset instance of the data train\n",
    "            num_epochs (int) : number of training epochs\n",
    "            batch_size (int) : number of batch size\n",
    "            device (string) : device type \n",
    "        return:\n",
    "            model (nn.Module) : Model trained\n",
    "    \"\"\"\n",
    "    \n",
    "    # Build The DataLoader Object to make batches in training\n",
    "    trainloader = DataLoader(dataset=data_train,batch_size=batch_size,shuffle=True)\n",
    "    valloader = DataLoader(dataset=data_val,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "    \n",
    "    # number of iterations per epoch\n",
    "    n_iterations_train = math.ceil(len(trainloader))\n",
    "    n_iterations_val = math.ceil(len(valloader))\n",
    "    \n",
    "    # to store errors\n",
    "    train_err = []\n",
    "    val_err = []\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_error = 0\n",
    "        for i, (x_train,y_train) in enumerate(trainloader): \n",
    "            x_train,y_train = x_train.to(device), y_train.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_train)\n",
    "            l = loss(output,y_train)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_error += l.item()\n",
    "            scheduler.step()\n",
    "        train_error_avg = train_error/n_iterations_train\n",
    "        print(\"Train ------> epoch : {0}/{1}, loss : {2}\".format(epoch+1,num_epochs,train_error_avg))\n",
    "        train_err.append(train_error_avg)\n",
    "\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            val_error = 0\n",
    "            for i, (x_val, y_val) in enumerate(valloader):\n",
    "                x_val, y_val = x_val.to(device), y_val.to(device)\n",
    "                output = model.eval()(x_val)\n",
    "                l = loss(output,y_val)\n",
    "                val_error += l.item()\n",
    "             \n",
    "            val_error_avg = val_error/n_iterations_val\n",
    "            print(\"Test ------> epoch : {0}/{1}, loss : {2}\".format(epoch+1,num_epochs,val_error_avg))\n",
    "            val_err.append(val_error_avg)\n",
    "            \n",
    "        print(\"-\"*50)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ------> epoch : 1/15, loss : 5.885665271186829\n",
      "Test ------> epoch : 1/15, loss : 3.057183710530924\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 2/15, loss : 1.2341171572208405\n",
      "Test ------> epoch : 2/15, loss : 0.9678949641343504\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 3/15, loss : 0.9791392740726471\n",
      "Test ------> epoch : 3/15, loss : 1.022942782210085\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 4/15, loss : 1.4182814273834228\n",
      "Test ------> epoch : 4/15, loss : 1.389854781924726\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 5/15, loss : 1.3238926378250122\n",
      "Test ------> epoch : 5/15, loss : 1.4291361602731407\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 6/15, loss : 1.3002923362255097\n",
      "Test ------> epoch : 6/15, loss : 1.2559016405964811\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 7/15, loss : 1.224025916337967\n",
      "Test ------> epoch : 7/15, loss : 1.1927002472237658\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 8/15, loss : 1.1280857843875884\n",
      "Test ------> epoch : 8/15, loss : 1.1288535105534636\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 9/15, loss : 1.0576697469234466\n",
      "Test ------> epoch : 9/15, loss : 1.0491562700880983\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 10/15, loss : 1.0018149787902833\n",
      "Test ------> epoch : 10/15, loss : 0.9895380800143598\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 11/15, loss : 0.9623180801868438\n",
      "Test ------> epoch : 11/15, loss : 0.9541784814371469\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 12/15, loss : 0.935772007226944\n",
      "Test ------> epoch : 12/15, loss : 0.9311837713939314\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 13/15, loss : 0.915328489112854\n",
      "Test ------> epoch : 13/15, loss : 0.923978923989561\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 14/15, loss : 0.8986952973842621\n",
      "Test ------> epoch : 14/15, loss : 0.9154652261886352\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 15/15, loss : 0.88122094643116\n",
      "Test ------> epoch : 15/15, loss : 0.9149227363232988\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Downloading the raiting DataFrame\n",
    "dataPath = \"./Data/ratings.db\"\n",
    "split_data = {\"test_size\" : 0.2, \"random_state\" : 848}\n",
    "\n",
    "# Defining the Dataset objects for training and validation \n",
    "data_train = movieDataset(dataPath,transform=ToTensor(),split_data=split_data)\n",
    "data_val = movieDataset(dataPath,transform=ToTensor(),train = False,split_data=split_data)\n",
    "\n",
    "# Hyperparameters of the CollFilt Model and the training\n",
    "n_users = data_train.n_users\n",
    "n_movies = data_train.n_movies\n",
    "n_factors = 50\n",
    "device = \"cuda\"\n",
    "weight_decay=0.001\n",
    "output_range=(0,5.5)\n",
    "num_epochs = 15\n",
    "batch_size = 64\n",
    "    \n",
    "# Instanciating the model\n",
    "model = CollFilt(n_users, n_movies, n_factors,output_range).to(device)\n",
    "\n",
    "# Defining optimizer and learning rate scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters() , weight_decay = weight_decay)\n",
    "scheduler = lr_scheduler.OneCycleLR(optimizer,\n",
    "                                        max_lr=0.05,\n",
    "                                        steps_per_epoch=math.ceil(len(data_train)/batch_size),\n",
    "                                        epochs = num_epochs)\n",
    "# Defining the loss function\n",
    "loss = nn.MSELoss()\n",
    "# Training\n",
    "model_trained = train_model(model, loss, optimizer, scheduler, data_train, data_val,\n",
    "                                num_epochs = num_epochs, batch_size = batch_size, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained model\n",
    "torch.save(model_trained.state_dict(),\"./data/CollFilt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.- Training and Evaluating the Deep Colaborative Filtering Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollFiltDNN(nn.Module):\n",
    "    \"\"\" DNN initialisation\n",
    "        Args:\n",
    "            input_dim (Int): Input dimension\n",
    "            dict_arch (dict): DNN architecture\n",
    "    \"\"\"\n",
    "    def __init__(self,n_users,n_movies,n_factors,dict_arch,output_range):\n",
    "        super(CollFiltDNN,self).__init__()\n",
    "        self.output_range = output_range\n",
    "        self.n_users = n_users\n",
    "        self.n_movies = n_movies\n",
    "        self.n_factors = n_factors\n",
    "        \n",
    "        self.dict_arch = dict_arch\n",
    "        \n",
    "        self.user_factors = nn.Embedding(n_users, n_factors)\n",
    "        self.movie_factors = nn.Embedding(n_movies, n_factors)\n",
    "        \n",
    "        # Define layers \n",
    "        self.layer1 = nn.Sequential(\n",
    "                        nn.Linear(self.n_factors+self.n_factors,self.dict_arch[\"layer1\"][\"input_dim\"]),\n",
    "                        nn.ReLU(),\n",
    "                    )\n",
    "       \n",
    "        self.layer2 = nn.Sequential(\n",
    "                        nn.Linear(self.dict_arch[\"layer1\"][\"input_dim\"],self.dict_arch[\"layer2\"][\"input_dim\"]),\n",
    "                    )\n",
    "        \n",
    "        self.dnn = nn.Sequential(self.layer1,self.layer2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    \n",
    "    \"\"\" Forward pass\n",
    "        Args (torch.Tensor) : Tensor input\n",
    "    \n",
    "    \"\"\"\n",
    "    def forward(self,t_input):\n",
    "        embs = torch.cat((self.user_factors(t_input[:,0]),self.movie_factors(t_input[:,1])),dim=1)\n",
    "        output = self.dnn(embs)\n",
    "        return self.sigmoid_range(output, self.output_range)[:,0]\n",
    "    \n",
    "    def sigmoid_range(self,t_input,output_range):\n",
    "        min_val, max_val = output_range\n",
    "        return (max_val - min_val)*self.sigmoid(t_input) + min_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ------> epoch : 1/10, loss : 1.1636343507766724\n",
      "Test ------> epoch : 1/10, loss : 1.095729754374812\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 2/10, loss : 1.1025759984970094\n",
      "Test ------> epoch : 2/10, loss : 1.138197036977774\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 3/10, loss : 1.1396670305728913\n",
      "Test ------> epoch : 3/10, loss : 1.1455845244395466\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 4/10, loss : 1.1489651902675628\n",
      "Test ------> epoch : 4/10, loss : 1.1455545756763543\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 5/10, loss : 1.1430324817657471\n",
      "Test ------> epoch : 5/10, loss : 1.1247207034891025\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 6/10, loss : 1.1215561754703522\n",
      "Test ------> epoch : 6/10, loss : 1.1010827347874261\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 7/10, loss : 1.0850036529064178\n",
      "Test ------> epoch : 7/10, loss : 1.0578421417135782\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 8/10, loss : 1.032787413263321\n",
      "Test ------> epoch : 8/10, loss : 0.9986559782927029\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 9/10, loss : 0.9632574696540832\n",
      "Test ------> epoch : 9/10, loss : 0.9305210014501699\n",
      "--------------------------------------------------\n",
      "Train ------> epoch : 10/10, loss : 0.8990871903419495\n",
      "Test ------> epoch : 10/10, loss : 0.9060902389855431\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "dataPath = \"./Data/ratings.db\"\n",
    "split_data = {\"test_size\" : 0.2, \"random_state\" : 848}\n",
    "    \n",
    "data_train = movieDataset(dataPath,transform=ToTensor(),split_data=split_data)\n",
    "data_val = movieDataset(dataPath,transform=ToTensor(),train = False,split_data=split_data)\n",
    "    \n",
    "n_users = data_train.n_users\n",
    "n_movies = data_train.n_movies\n",
    "n_factors = 50\n",
    "device = \"cuda\"\n",
    "weight_decay=0.01\n",
    "output_range=(0,5.5)\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "    \n",
    "    \n",
    "dict_arch = {\n",
    "    \"layer1\": {\"input_dim\":100},\n",
    "    \"layer2\": {\"input_dim\":1}\n",
    "}\n",
    "\n",
    "\n",
    "# Instanciating the model\n",
    "model = CollFiltDNN(n_users, n_movies, n_factors, dict_arch, output_range).to(device)\n",
    "    \n",
    "    \n",
    "# Defining optimizer and a learning rate scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters() , weight_decay = weight_decay)\n",
    "scheduler = lr_scheduler.OneCycleLR(optimizer,\n",
    "                                        max_lr=0.05,\n",
    "                                        steps_per_epoch=math.ceil(len(data_train)/batch_size),\n",
    "                                        epochs = num_epochs)\n",
    "# Defining the loss function    \n",
    "loss = nn.MSELoss()\n",
    "# Training\n",
    "model_trained = train_model(model, loss, optimizer, scheduler, data_train, data_val,\n",
    "                                num_epochs = num_epochs, batch_size = batch_size, device = device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
